{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Extraction\n",
    "\n",
    "This notebook contains my investigations into creating knowledge graphs using LlamaIndex, LangChain, and Neo4j.  My goal is to produce a repeatable pattern for knowledge graph generation template that can be applied across many use cases. \n",
    "\n",
    "## Theory/Process\n",
    "\n",
    "As I understand the process from my research the primary steps we need to take in order to go from unstructured data (such as a website, book, article, video, image, etc) to structures graph data is the following:\n",
    "\n",
    "1. Pull the data into the application\n",
    "2. Create representations of that unstructured data as a graph\n",
    "3. Upload that data to our graph database (Neo4j in my case)\n",
    "4. Query that data for RAG\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "First we need to import some dependencies from LangChain and LlamaIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import BaseNode, TextNode\n",
    "from llama_index.readers.web  import SimpleWebPageReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import modules related to HTML parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag, SoupStrainer\n",
    "from markdownify import markdownify as md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have some additional custom modules that I am using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.log_utils import markdownTable\n",
    "from src.llm import ollama, jsonOutputFixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some base modules we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our libraries imported we can setup a couple of utility functions which will make life easier for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Utility Functions\n",
    "\n",
    "def executionTimer() -> Callable:\n",
    "  \"\"\"\n",
    "  A function timing utility.  This curry function will record a start time when called, then when the inner function is called will return the duration between the 2 calls.\n",
    "  \"\"\"\n",
    "  start = time.perf_counter()\n",
    "  def executionTimerEnd() -> str:\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    return f'{end - start:0.2f} sec'\n",
    "\n",
    "def stringCleanUp(chunk: str, replacers: list[tuple[str, str, re.RegexFlag]]):\n",
    "  \"\"\"\n",
    "  A wrapper function around the 're' modules \"#sub\" method.  This allows us to make multiple edits to a string\n",
    "  \"\"\"\n",
    "  output = chunk;\n",
    "\n",
    "  for replacer in replacers:\n",
    "    flags = re.NOFLAG\n",
    "    if (len(replacer) == 3):\n",
    "      flags = replacer[2]\n",
    "\n",
    "    output = re.sub(replacer[0], replacer[1], output, flags=flags)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the setup I am going to create a Node list that I can use down in the node processing.  This should let me experiment with multiple different types of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes: list[BaseNode] = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Utilities\n",
    "\n",
    "As part of this process I am designing, we will want to fetch data from web browsers.  The example I am using is the [Dungeons & Dragons 5e SRD](https://5esrd.com).\n",
    "\n",
    "The functions we are setting up here are:\n",
    "\n",
    "| Function | Description |\n",
    "| :-: | --- |\n",
    "| extractElements | Pulls elements based on the provided arguments and returns them as a list |\n",
    "| removeElements | Pulls elements based on the provided arguments but returns nothing |\n",
    "| htmlToMarkdown | Converts our HTML document to Markdown by abstracting the heading style from the `markdownify` lib |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML Utility Functions\n",
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "BeautifulSoupSearch = TypedDict(\n",
    "  'HTMLSearch',\n",
    "  {\n",
    "    'name': SoupStrainer,\n",
    "    'attrs': SoupStrainer,\n",
    "    'recursive': bool,\n",
    "    'string': SoupStrainer\n",
    "  }\n",
    ")\n",
    "\n",
    "def extractElements(html: Tag, search: BeautifulSoupSearch):\n",
    "  output: list[Tag] = list()\n",
    "  elements = html.findAll(\n",
    "    name=search.get('name'),\n",
    "    attr=search.get('attrs'),\n",
    "    recursive=search.get('recursive') or True,\n",
    "    string=search.get('string')\n",
    "  )\n",
    "\n",
    "  for elem in elements:\n",
    "    output.append(elem.extract());\n",
    "\n",
    "  return output;\n",
    "\n",
    "def removeElements(html: Tag, search: BeautifulSoupSearch):\n",
    "  extractElements(html, search)\n",
    "\n",
    "def htmlToMarkdown(html: str):\n",
    "  rawMdStr = md(str(html), heading_style=\"ATX\")\n",
    "  return stringCleanUp(\n",
    "    rawMdStr,\n",
    "    [\n",
    "      [r'\\n{3,}', '\\n\\n'],      # Remove excessive new lines\n",
    "      [r'â', '-'],              # Remove unicode character\n",
    "      [r'', ''],               # Remove unicode character\n",
    "      [r'\\x94', '', re.UNICODE] # Remove unicode character\n",
    "    ]\n",
    "  )\n",
    "\n",
    "def cleanupWebsite():\n",
    "  ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "With our utilities in place, we can now load the actual html.  Under the hood I am using `SimpleWebPageReader` from LlamaIndex.  The goal with this process is to support recursive loading of documents by allowing for links to be extracted from the text.  This does mean that we are loading/evaluating web pages one at a time but this is more memory friendly than loading the whole website and then parsing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWebsite(\n",
    "    url: str,\n",
    "    contentTag: str = None,\n",
    "    excludedTags: list[BeautifulSoupSearch] | None = None,\n",
    "    extractTags: dict[str, BeautifulSoupSearch] = None,\n",
    "    extractLinks: bool | str = False\n",
    "):\n",
    "  # Pull in html using LlamaIndex Loader\n",
    "  page = SimpleWebPageReader().load_data([url]).pop()\n",
    "\n",
    "  # The 'page' is a string so we need to convert that to HTML.\n",
    "  # BeautifulSoup can help us with that\n",
    "  html = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "  # Depending on the URL you may get better results by \n",
    "  if (contentTag):\n",
    "    html = html.find(contentTag)\n",
    "\n",
    "  # Setup the extracted tags dict\n",
    "  extractedTags: dict[str, list[str]] = dict()\n",
    "\n",
    "  # Links are a valuable part of parsing process.  This motivates\n",
    "  # the option for links to be its own extraction task as opposed\n",
    "  # requiring the user enter a BeautifulSoup query for links\n",
    "  if (isinstance(extractLinks, str) or extractLinks == True):\n",
    "    links = list()\n",
    "    for link in html.findAll(f'a', href=True):\n",
    "      # If a string is passed, then we want to filter on that string\n",
    "      if (isinstance(extractLinks, str)):\n",
    "        if (link['href'].startswith(extractLinks)):\n",
    "          links.append(link['href'])\n",
    "      else:\n",
    "        links.append(link['href'])\n",
    "    \n",
    "    extractedTags['a'] = links\n",
    "\n",
    "  # If the extract tags arg has been provided, we want to go\n",
    "  # find any instance of the search and return it as part of\n",
    "  # the dict.\n",
    "  if (extractTags):\n",
    "    # Get the keys from the parameter\n",
    "    keys = extractTags.keys();\n",
    "    # Create a new dict using those keys\n",
    "    for key, val in zip(keys, [list()]*len(keys)):\n",
    "      extractedTags[key] = val\n",
    "\n",
    "    for key in keys:\n",
    "      search = extractTags[key]\n",
    "      # Returns a list of html elements that match\n",
    "      elements = extractElements(html, search)\n",
    "\n",
    "      # All data should be markdown so we are going to\n",
    "      # run the htmlToMarkdown cleanup\n",
    "      for elem in elements:\n",
    "        extractedTags[key].append(htmlToMarkdown(str(elem)))\n",
    "\n",
    "  # If excluded strings have been provided, we need to remove\n",
    "  # those from the HTML.  These will be HTML tags such as 'script'\n",
    "  # or 'div'\n",
    "  if (excludedTags):\n",
    "    [removeElements(html, search) for search in excludedTags]\n",
    "  \n",
    "  # Once we have extracted all of the tags we have our \"final\"\n",
    "  # HTML document that we can then convert into markdown\n",
    "  markdown = htmlToMarkdown(str(html))\n",
    "\n",
    "  return markdown, extractedTags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Html Extraction\n",
    "\n",
    "Now that we have our downloader process setup, we can go ahead and verify that we are able to download the website (as markdown).  I have configured the website loader to extract links and tables from the html before parsing to markdown.\n",
    "\n",
    "The **links** are extracted so that we can recursively fetch additional pages if we would like.  The **tables** were extracted on a hunch that they may mess with our ability to generate chunks as we could end up with 1/2 a table in one chunk and another have in another chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Index | Value |\n",
      "| --- | --- |\n",
      "| Website MD Size | 23139 |\n",
      "| Extracted Elements | a, tables |\n",
      "| Links Found | 67 |\n",
      "| Tables Found | 6 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SOURCE_URL = \"https://www.5esrd.com/classes\"\n",
    "\n",
    "websiteMd, tagMap = loadWebsite(\n",
    "  SOURCE_URL,\n",
    "  contentTag=\"main\",\n",
    "  excludedTags=[\n",
    "    { \"name\": \"script\" },\n",
    "    { \"name\": \"div\", \"attrs\": { \"id\": \"toc_container\" }}\n",
    "  ],\n",
    "  extractTags={ \"tables\": { \"name\": \"table\" } },\n",
    "  extractLinks=SOURCE_URL\n",
    ")\n",
    "\n",
    "linkLength = 0\n",
    "if tagMap.get('a'):\n",
    "  linkLength = len(tagMap.get('a')) \n",
    "\n",
    "print(markdownTable(\n",
    "  ['Index', 'Value'],\n",
    "  [\n",
    "    [ 'Website MD Size', len(websiteMd) ],\n",
    "    [ 'Extracted Elements', ', '.join(list(tagMap.keys())) ],\n",
    "    [ 'Links Found', linkLength],\n",
    "    [ 'Tables Found', len(tagMap.get('tables')) if tagMap.get('tables') else 'N/A' ]\n",
    "  ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing\n",
    "\n",
    "The next main step in the process is the conversion of the unstructured data.  There are a couple of techniques I am going to explore here.  Those techniques are:\n",
    "\n",
    "| Type | Description |\n",
    "| :-: | --- |\n",
    "| Recursive | Split on a list of user defined characters (recommended by LangChain) |\n",
    "| Markdown Header | Splits text based on Markdown-specific characters. Notably, this adds in relevant information about where that chunk came from (based on the Markdown) |\n",
    "| Semantic | First splits on sentences. Then combines ones next to each other if they are semantically similar enough. Taken from Greg Kamradt - Currently marked as _Experimental_ in the LangChain Docs |\n",
    "| Custom Markdown Header | A home rolled solution for chunking that is based on my own technique |\n",
    "\n",
    "To test each implementation, I wrapped in a function which returns a LangChain `Document` list.  This standard interface allows us to test each technique using a higher order function.\n",
    "\n",
    "First we setup our question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorQuestion = 'What is the purpose of levels?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the first 3 wrapped in a the standard interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from llama_index_client import Document\n",
    "from src.llm import get_service_context\n",
    "\n",
    "\n",
    "def recursiveTextSplitter(markdown: str) -> list[Document]:\n",
    "  splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "  )\n",
    "\n",
    "  return splitter.create_documents([markdown])\n",
    "\n",
    "def markdownTextSplitter(markdown: str) -> list[Document]:\n",
    "  splitter = MarkdownHeaderTextSplitter(\n",
    "    strip_headers=False,\n",
    "    headers_to_split_on = [\n",
    "      (\"#\", \"Header 1\"),\n",
    "      (\"##\", \"Header 2\"),\n",
    "      (\"###\", \"Header 3\"),\n",
    "      (\"####\", \"Header 4\"),\n",
    "      (\"#####\", \"Header 5\"),\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  return splitter.split_text(markdown)\n",
    "\n",
    "def semanticTextSplitter(markdown: str) -> list[Document]:\n",
    "  splitter = SemanticChunker(OllamaEmbeddings(model=\"mistral:7b\"))\n",
    "  return splitter.create_documents([markdown])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the custom implementation that I wrote myself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitMdByParagraph(markdownText: str, chunkList: list[str]):\n",
    "  chunkList.extend(re.split('\\n\\n', markdownText))\n",
    "\n",
    "def splitMdByHeader(markdownText: str, depth: int) -> list[str]:\n",
    "  pattern = r'^#{' + str(depth) + r'}\\s.*$'\n",
    "  return re.split(pattern, markdownText, flags=re.MULTILINE)\n",
    "\n",
    "def markdownHeaderParser(markdown: str, chunkList: list[str] = None, depth: int = None, max_chunk_size: int = None) -> list[str]:\n",
    "  if (not depth):\n",
    "    depth = 1\n",
    "\n",
    "  if (not max_chunk_size):\n",
    "    max_chunk_size = 500\n",
    "\n",
    "  if (not chunkList):\n",
    "    chunkList = list()\n",
    "\n",
    "  subStrings = splitMdByHeader(markdown, depth)\n",
    "\n",
    "  for documentPart in subStrings:\n",
    "    if (len(documentPart) < max_chunk_size):\n",
    "      chunkList.extend([documentPart])\n",
    "    elif depth <= 5:\n",
    "      newDepth = depth + 1\n",
    "      markdownHeaderParser(documentPart, chunkList, depth=newDepth, max_chunk_size=max_chunk_size)\n",
    "    else:\n",
    "      splitMdByParagraph(documentPart, chunkList)\n",
    "\n",
    "  return list(filter(lambda chunk: len(chunk) > 0, chunkList))\n",
    "\n",
    "def customMarkdownTextSplitter(markdown: str) -> list[Document]:\n",
    "  chunks = markdownHeaderParser(markdown, max_chunk_size=1000)\n",
    "\n",
    "  documents: list[Document] = list()\n",
    "  for chunk in chunks:\n",
    "    documents.append(Document(chunk))\n",
    "\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add the evaluator function for text splitting.  This will take in the previously setup splitter wrapper functions and output the results as well as some timing information for us.  \n",
    "\n",
    "As part of the process we are crossing our streams a little bit and going from LangChain tooling over to LlamaIndex Embedding generation.  This is simply a product of my previous investigations where I started with LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langChainToLLamaIndex(langchainDocs: list[TextNode]) -> list[TextNode]:\n",
    "  llamaDocs: list[TextNode] = list()\n",
    "  for doc in langchainDocs:\n",
    "    llamaDocs.append(TextNode(text=doc.page_content))\n",
    "\n",
    "  return llamaDocs\n",
    "\n",
    "def textSplitterEvaluation(\n",
    "    fn: Callable[[str], list[Document]],\n",
    "    name: str,\n",
    "    fnInput: str,\n",
    "    prompt: str,\n",
    "    sourceName: str,\n",
    "    chatHistory: list[ChatMessage] = None\n",
    "):\n",
    "  output = dict({\n",
    "    'name': name,\n",
    "    'success': False,\n",
    "    'execution_msg': '',\n",
    "    'splitter_result': '',\n",
    "    'fn_execution_time': '',\n",
    "    'index': None,\n",
    "    'vector_execution_time': '',\n",
    "    'query_result': '',\n",
    "    'query_execution_time': ''\n",
    "  });\n",
    "\n",
    "  try:\n",
    "    tic = time.perf_counter()\n",
    "    output['splitter_result'] = fn(fnInput)\n",
    "    toc = time.perf_counter()\n",
    "    output['fn_execution_time'] = f'{toc - tic:0.2f} sec'\n",
    "\n",
    "    nodes = langChainToLLamaIndex(output['splitter_result'])\n",
    "\n",
    "    # Add url as metadata to each node\n",
    "    for node in nodes:\n",
    "      node.metadata['source'] = sourceName\n",
    "\n",
    "    output['nodes'] = nodes\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    index = VectorStoreIndex(nodes=output['nodes'], service_context=get_service_context())\n",
    "    toc = time.perf_counter()\n",
    "    output['vector_execution_time'] = f'{toc - tic:0.2f} sec'\n",
    "\n",
    "    queryEngine = index.as_chat_engine(\n",
    "      verbose=True,\n",
    "      chat_mode='best'\n",
    "    );\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    output['query_result'] = queryEngine.chat(\n",
    "      message=prompt,\n",
    "      chat_history=chatHistory\n",
    "    )\n",
    "    toc = time.perf_counter()\n",
    "    output['query_execution_time'] = f'{toc - tic:0.2f} sec'\n",
    "    \n",
    "    output['success'] = True\n",
    "    output['execution_msg'] = 'Success'\n",
    "  except KeyError as kErr:\n",
    "    output['execution_msg'] = f'Dict Key Lookup Err [KeyError]: {kErr}'\n",
    "    exit()\n",
    "  except Exception as err:\n",
    "    output['execution_msg'] = f'Error: {err.with_traceback()}'\n",
    "  finally:\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally with the setup out of the way, we can go ahead and test each technique.  This takes a minute as it generates the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The purpose of levels in the context of Dungeons & Dragons is to determine the number of spell slots a character has available for casting spells. The levels of the bard, cleric, druid, sorcerer, and wizard classes are added together, along with half of the character's levels in the paladin and ranger classes, to determine the total number of spell slots. This total is then consulted with the **Table: Multiclass Spellcaster** to determine the actual spell slots available to the character.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can use the `query_engine_tool` to get more information about the purpose of levels in Dungeons & Dragons.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels in D&D?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: In Dungeons & Dragons (D&D), levels refer to a character's progression and growth throughout their adventures. There are several purposes of levels in D&D:\n",
      "\n",
      "1. Character Progression: Levels represent a character's increasing power, skill, and abilities as they gain experience points through defeating enemies, completing quests, and overcoming challenges. As characters level up, they unlock new abilities, spells, and features that enhance their capabilities.\n",
      "2. Balancing Gameplay: Levels help maintain a balance between different character classes, races, and abilities. By limiting the number of levels a character can gain, the game ensures that no one class or race becomes too overpowered compared to others.\n",
      "3. Customization: Each level provides an opportunity for players to customize their characters according to their preferred playstyle. As characters progress through levels, they can choose new abilities, spells, and equipment that fit their character's personality and role in the party.\n",
      "4. Story Progression: Levels serve as a narrative tool, allowing players to progress through a story or campaign. As characters gain experience points and level up, they unlock new content, quests, and challenges that advance the story.\n",
      "5. Skill Development: Levels also represent a character's skill development. As characters gain experience points, they become more proficient in various skills, such as combat, magic, or persuasion. This progression is essential for creating immersive and realistic gameplay experiences.\n",
      "6. Balancing Combat: In combat encounters, levels help balance the power between different enemies and players. Enemies with higher levels pose a greater challenge to players, while lower-level enemies may be more manageable. This balance ensures that combat encounters are engaging and challenging without becoming too difficult or too easy.\n",
      "7. Representing Experience: Levels represent the amount of experience a character has gained throughout their adventures. As characters gain experience points, they progress through levels, demonstrating their growth and development as players.\n",
      "8. Unlocking New Features: Each level unlocks new features, abilities, or spells for characters to use. These new capabilities can provide fresh strategies, options, and challenges for players to explore.\n",
      "9. Creating Depth: Levels add depth to the game by providing a framework for character progression and growth. This structure allows players to experiment with different playstyles, abilities, and strategies, creating a more dynamic and engaging gaming experience.\n",
      "10. Encouraging Exploration: By offering new content, abilities, or spells at higher levels, the game encourages players to explore new areas, complete challenging quests, and push their characters to new heights. This exploration fosters a sense of discovery and accomplishment, enriching the overall gaming experience.\n",
      "\n",
      "In summary, levels in D&D serve multiple purposes, including character progression, balancing gameplay, customization, story progression, skill development, balancing combat, representing experience, unlocking new features, creating depth, and encouraging exploration. These functions work together to create a rich, engaging, and immersive gaming experience for players.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can use the `query_engine_tool` to get more information about the purpose of levels in Dungeons & Dragons.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels in D&D?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The purpose of levels in D&D is to determine a player character's abilities, capabilities, and potential for growth and development throughout the game. Levels are used to measure a character's progress and advancement in various areas, such as combat, spellcasting, and skill proficiencies.\n",
      "\n",
      "In D&D, characters start at level 1 and gain experience points (XP) as they complete quests, defeat enemies, and overcome challenges. As they accumulate XP, they gain levels, which unlock new abilities, spells, and other benefits. The higher the character's level, the more powerful and capable they become in combat and other areas of the game.\n",
      "\n",
      "Levels also serve as a way to balance gameplay among players. As characters gain levels, they become more formidable opponents for other players, while also providing opportunities for collaboration and strategic planning.\n",
      "\n",
      "In summary, levels in D&D are essential for creating a fun and engaging role-playing experience, allowing players to develop their characters and interact with each other in meaningful ways.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The purpose of levels in the context provided is to define the possible combinations of moral and personal attitudes that a creature can have in the game world. Levels are used to categorize creatures into one of nine alignments, which are lawful good, neutral good, chaotic good, lawful neutral, neutral, chaotic neutral, lawful evil, neutral evil, and chaotic evil. Each alignment has its own distinct behavior and characteristics, which are described in the context. The levels provide a framework for understanding the moral and personal attitudes of creatures in the game world, and help to create a more immersive and realistic gaming experience.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: Ah, I see! So levels in this context refer to the different categories or alignments that creatures can have based on their moral and personal attitudes. It sounds like a useful tool for creating a more immersive and realistic game world!\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What are some examples of levels in the context of the game?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: I'm just an AI, I don't have access to any external information or prior knowledge, so my answers will always be based on the provided context alone.\n",
      "\n",
      "In this case, you've given me a query asking for examples of levels in the context of the game. However, the context information doesn't provide any specific details about levels. Therefore, I cannot provide any examples of levels without additional information.\n",
      "\n",
      "To answer your query more effectively, could you please provide more context or clarify what you mean by \"levels\" in this context?\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Levels are a fundamental aspect of the game mechanics in Dungeons & Dragons. They represent the character's progression and growth over time, as they gain experience points (XP) through various activities such as completing quests, defeating enemies, or exploring new areas.\n",
      "\n",
      "As a player gains XP, they advance to higher levels, which unlock new abilities, spells, and other game mechanics that can be used to enhance their character's capabilities. Leveling up also provides players with additional hit points, strength, intelligence, and other attributes that contribute to their character's overall power and effectiveness in the game world.\n",
      "\n",
      "In essence, levels are a way to track a player's progress and growth throughout the campaign, providing a sense of progression and accomplishment as they advance through the game.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools.\n",
      "Answer: Levels in Dungeons & Dragons represent a character's progression and growth over time, unlocking new abilities, spells, and mechanics as they gain experience points through various activities. Leveling up provides players with additional hit points, strength, intelligence, and other attributes that contribute to their character's overall power and effectiveness in the game world. The levels provide a sense of progression and accomplishment as players advance through the campaign.\n",
      "\u001b[0m| Name | Success | Splitter Time | Index Time | Query Time |\n",
      "| --- | --- | --- | --- | --- |\n",
      "| Recursive | False | 0.00 sec | 26.36 sec |  |\n",
      "| Markdown Header | False | 0.00 sec | 15.27 sec |  |\n",
      "| Custom Markdown Header | False |  |  |  |\n",
      "| Semantic | True | 61.20 sec | 13.16 sec | 13.53 sec |\n",
      "\n",
      "\n",
      "**Recursive**\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "**Markdown Header**\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "**Custom Markdown Header**\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "**Semantic**\n",
      "```\n",
      "Levels in Dungeons & Dragons represent a character's progression and growth over time, unlocking new abilities, spells, and mechanics as they gain experience points through various activities. Leveling up provides players with additional hit points, strength, intelligence, and other attributes that contribute to their character's overall power and effectiveness in the game world. The levels provide a sense of progression and accomplishment as players advance through the campaign.\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testResults = dict({\n",
    "  'recursive': textSplitterEvaluation(recursiveTextSplitter, 'Recursive', websiteMd, evaluatorQuestion, SOURCE_URL),\n",
    "  'markdown_header': textSplitterEvaluation(markdownTextSplitter, 'Markdown Header', websiteMd, evaluatorQuestion, SOURCE_URL),\n",
    "  'custom_markdown_header': textSplitterEvaluation(customMarkdownTextSplitter, 'Custom Markdown Header', websiteMd, evaluatorQuestion, SOURCE_URL),\n",
    "  'semantic': textSplitterEvaluation(semanticTextSplitter, 'Semantic', websiteMd, evaluatorQuestion, SOURCE_URL)\n",
    "})\n",
    "\n",
    "resultHeaders = ['Name', 'Success', 'Splitter Time', 'Index Time', 'Query Time']\n",
    "resultTable = []\n",
    "resultDisplay = [];\n",
    "\n",
    "for recordKey in testResults.keys():\n",
    "  result = testResults[recordKey]\n",
    "  resultTable.append(\n",
    "    [ result['name'], result['success'], result['fn_execution_time'], result['vector_execution_time'], result['query_execution_time'] ]\n",
    "  )\n",
    " \n",
    "  msg = ''\n",
    "  if (result['success']):\n",
    "    msg = result['query_result']\n",
    "  else:\n",
    "    msg = result['execution_msg']\n",
    "\n",
    "  resultDisplay.append('**{}**\\n```\\n{}\\n```\\n\\n'.format(result['name'], msg))\n",
    "\n",
    "print(markdownTable(\n",
    "  headers=resultHeaders,\n",
    "  values=resultTable\n",
    "))\n",
    "\n",
    "print(''.join(resultDisplay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Results\n",
    "\n",
    "| Name | Success | Splitter Time | Index Time | Query Time |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Recursive | True | 0.00 sec | 30.52 sec | 4.56 sec |\n",
    "| Markdown Header | True | 0.00 sec | 20.10 sec | 15.92 sec |\n",
    "| Custom Markdown Header | False |  |  |  |\n",
    "| Semantic | True | 67.77 sec | 13.30 sec | 7.06 sec |\n",
    "\n",
    "\n",
    "**Recursive**\n",
    "```\n",
    "The purpose of levels in the context of Dungeons & Dragons is to represent a character's advancement and growth as they gain experience points (XP) and increase their proficiency bonus. As a character gains levels, their hit point maximum increases, and they gain access to new spells and abilities. The levels also determine the character's available spell slots, which are used to cast spells. Overall, the levels system is designed to provide a framework for characters to grow and develop as they progress through the game.\n",
    "```\n",
    "\n",
    "**Markdown Header**\n",
    "```\n",
    "Levels in D&D serve several purposes:\n",
    "\n",
    "1. Progression: Levels allow players to progress their characters over time, gaining new abilities, skills, and powers as they increase in level. This progression provides a sense of accomplishment and growth for the player and their character.\n",
    "2. Balance: By limiting the power of lower-level characters compared to higher-level ones, levels help maintain balance in gameplay. As players gain experience and defeat challenges, their characters become stronger and more capable, allowing them to tackle increasingly difficult content.\n",
    "3. Customization: Each level provides new options for character customization, such as additional spells or abilities. This allows players to tailor their characters to fit their preferred playstyle and the needs of their party.\n",
    "4. Storytelling: Levels can be used to drive the story forward by providing challenges and obstacles that must be overcome. As players progress through levels, they encounter more difficult enemies, uncover new plot points, or discover hidden secrets.\n",
    "5. Skill development: Each level provides an opportunity for players to develop their character's skills further. Whether it's learning new spells, improving combat abilities, or mastering a particular tool or weapon, levels allow players to grow and improve their characters over time.\n",
    "6. Character growth: Levels provide a framework for character growth, allowing players to explore new abilities, develop their characters' personalities, and create meaningful connections with other characters in the game world.\n",
    "7. Replayability: The leveling system encourages replayability by providing different challenges and experiences each time a player starts a new character or campaign. This helps keep the game fresh and exciting, even for experienced players.\n",
    "8. Roleplaying opportunities: Levels can be used to create roleplaying opportunities, such as character milestones, achievements, or setbacks. These moments can help deepen the player's connection with their character and enhance the overall roleplaying experience.\n",
    "9. Mechanical progression: Levels provide a mechanical framework for advancement, allowing players to unlock new abilities, spells, or items as they progress through the game. This progression helps maintain interest and challenge throughout the game.\n",
    "10. Player satisfaction: Finally, levels can provide a sense of accomplishment and satisfaction for players as they progress through the game, overcoming challenges and achieving new milestones. This satisfaction can help keep players engaged and motivated to continue playing.\n",
    "```\n",
    "\n",
    "**Custom Markdown Header**\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "**Semantic**\n",
    "```\n",
    "The purpose of levels in the context of the given information is to determine the number of spell slots a multiclass spellcaster has available for casting spells at each spell level. The levels are used to calculate the number of spell slots gained from each class, and the resulting total number of spell slots available for casting spells at each spell level.\n",
    "\n",
    "For example, a 10th-level multiclass spellcaster would have 4 spell slots available at 1st level, 3 spell slots available at 2nd level, and so on, until they reach their highest level (10th) where they have 4 spell slots available. This allows the spellcaster to cast spells of increasing difficulty and power as they gain experience and level up.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic + Tables\n",
    "\n",
    "One curiosity I had while working on on the chunking step was _if_ the markdown tables could improve the vectors within the _Semantic_ chunker.  I had initially setup the parser to remove them because in my _Custom Markdown_ approach I was trying to avoid them being separated.  And with the text-based (token-based) chunkers, this was a high likely hood.  \n",
    "\n",
    "So next I went ahead and created an alternative html document where I skipped the table extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'What is the purpose of levels?', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The purpose of levels in the context provided is to determine the number of spell slots a multiclass spellcaster has available for casting spells at each spell level. The levels are used to calculate the number of spell slots gained from each class, and the resulting total number of spell slots available for casting spells at each spell level.\n",
      "\n",
      "For example, a 10th-level multiclass spellcaster has 4 spell slots available at 1st level, 3 spell slots available at 2nd level, and so on. This allows the spellcaster to cast more complex and powerful spells as they gain experience and level up.\n",
      "\n",
      "In addition to determining the number of spell slots available, levels also affect other abilities and features of a multiclass spellcaster, such as their ability to cast certain spells or use specific magic items.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools.\n",
      "Answer: The purpose of levels in the context provided is to determine the number of spell slots a multiclass spellcaster has available for casting spells at each spell level, and to affect other abilities and features of the spellcaster.\n",
      "\u001b[0m| Name | Success | Splitter Time | Index Time | Query Time |\n",
      "| --- | --- | --- | --- | --- |\n",
      "| SemanticTextSplitterWithTables | True | 73.33 sec | 13.48 sec | 14.62 sec |\n",
      "| Semantic | True | 61.20 sec | 13.16 sec | 13.53 sec |\n",
      "\n",
      "\n",
      "**SemanticTextSplitterWithTables**\n",
      "```\n",
      "The purpose of levels in the context provided is to determine the number of spell slots a multiclass spellcaster has available for casting spells at each spell level, and to affect other abilities and features of the spellcaster.\n",
      "```\n",
      "\n",
      "\n",
      "**Semantic**\n",
      "```\n",
      "Levels in Dungeons & Dragons represent a character's progression and growth over time, unlocking new abilities, spells, and mechanics as they gain experience points through various activities. Leveling up provides players with additional hit points, strength, intelligence, and other attributes that contribute to their character's overall power and effectiveness in the game world. The levels provide a sense of progression and accomplishment as players advance through the campaign.\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "websiteMdWithTables, tagMap = loadWebsite(\n",
    "  SOURCE_URL,\n",
    "  contentTag=\"main\",\n",
    "  excludedTags=[\n",
    "    { \"name\": \"script\" },\n",
    "    { \"name\": \"div\", \"attrs\": { \"id\": \"toc_container\" }}\n",
    "  ],\n",
    "  extractLinks=SOURCE_URL\n",
    ")\n",
    "\n",
    "semanticTableResult = textSplitterEvaluation(semanticTextSplitter, 'SemanticTextSplitterWithTables', websiteMdWithTables, evaluatorQuestion, SOURCE_URL)\n",
    "\n",
    "print(markdownTable(\n",
    "  headers=resultHeaders,\n",
    "  values=[\n",
    "    [ semanticTableResult['name'], semanticTableResult['success'], semanticTableResult['fn_execution_time'], semanticTableResult['vector_execution_time'], semanticTableResult['query_execution_time'] ],\n",
    "    [ testResults['semantic']['name'], testResults['semantic']['success'], testResults['semantic']['fn_execution_time'], testResults['semantic']['vector_execution_time'], testResults['semantic']['query_execution_time'] ]\n",
    "  ]\n",
    "))\n",
    "\n",
    "print('**{}**\\n```\\n{}\\n```\\n\\n'.format(semanticTableResult['name'], semanticTableResult['query_result'] if semanticTableResult['success'] else semanticTableResult['execution_msg'] ))\n",
    "print('**{}**\\n```\\n{}\\n```\\n\\n'.format(testResults['semantic']['name'], testResults['semantic']['query_result'] if testResults['semantic']['success'] else testResults['semantic']['execution_msg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some example results form that test.  It does seem that with additional context I can \n",
    "\n",
    "| Name | Success | Splitter Time | Index Time | Query Time |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| SemanticTextSplitterWithTables | True | 67.30 sec | 13.29 sec | 7.46 sec |\n",
    "| Semantic | True | 67.77 sec | 13.30 sec | 7.06 sec |\n",
    "\n",
    "\n",
    "**SemanticTextSplitterWithTables**\n",
    "```\n",
    "The purpose of levels in the context of spell slots and alignment is to provide a framework for determining the maximum number of spells a creature can cast per day, based on their level of proficiency and their alignment. The levels represent different stages of proficiency and power, with higher levels corresponding to more powerful and skilled creatures.\n",
    "\n",
    "In the context of Pact Magic, levels also determine the number of spell slots available for casting spells from other classes. This allows creatures with both the Spellcasting class feature and the Pact Magic class feature to combine their own spells with those of other classes, creating a more diverse and powerful magical repertoire.\n",
    "\n",
    "Overall, levels in this context serve as a way to track a creature's progress and abilities, and to provide a framework for determining their maximum potential for spellcasting and magic use.\n",
    "```\n",
    "\n",
    "\n",
    "**Semantic**\n",
    "```\n",
    "The purpose of levels in the context of the given information is to determine the number of spell slots a multiclass spellcaster has available for casting spells at each spell level. The levels are used to calculate the number of spell slots gained from each class, and the resulting total number of spell slots available for casting spells at each spell level.\n",
    "\n",
    "For example, a 10th-level multiclass spellcaster would have 4 spell slots available at 1st level, 3 spell slots available at 2nd level, and so on, until they reach their highest level (10th) where they have 4 spell slots available. This allows the spellcaster to cast spells of increasing difficulty and power as they gain experience and level up.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposition Extraction\n",
    "\n",
    "Recently I was watching a [video](https://www.youtube.com/watch?v=8OJC21T2SL4) on text extraction techniques and one technique that was proposed as a solution was based off of this [research paper](https://arxiv.org/abs/2312.06648) which suggests converting the text into propositions (a statement or assertion that expresses a judgment or opinion).  \n",
    "\n",
    "As a product of the paper is a prompt which has been published on LangChain's LangSmith Hub: [Link](https://smith.langchain.com/hub/wfh/proposal-indexing).\n",
    "\n",
    "Below is a splitter function which process the text into propositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsupported message type: <class 'llama_index.core.base.llms.types.ChatMessage'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m Llama2LangChain \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral:7b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m test \u001b[38;5;241m=\u001b[39m proposition\u001b[38;5;241m.\u001b[39mPropositionPrompt()\n\u001b[0;32m----> 8\u001b[0m propWebsitePrompt \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreatePrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebsiteMd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(propWebsitePrompt))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(markdownTable(\n\u001b[1;32m     13\u001b[0m   headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m   values\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m   ]\n\u001b[1;32m     18\u001b[0m ))\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/src/prompts/proposition.py:93\u001b[0m, in \u001b[0;36mPropositionPrompt.createPrompt\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreatePrompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessageRole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/prompts/chat.py:748\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[0;34m(cls, messages)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    712\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    713\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/prompts/chat.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    712\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    713\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/prompts/chat.py:958\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    954\u001b[0m         _message \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[1;32m    955\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(cast(\u001b[38;5;28mstr\u001b[39m, template))\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _message\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsupported message type: <class 'llama_index.core.base.llms.types.ChatMessage'>"
     ]
    }
   ],
   "source": [
    "from src.prompts import proposition\n",
    "from src.llm import ollama\n",
    "from langchain.llms.ollama import Ollama\n",
    "\n",
    "Llama2LangChain = Ollama(model=\"mistral:7b\")\n",
    "test = proposition.PropositionPrompt()\n",
    "\n",
    "propWebsitePrompt = test.createPrompt(websiteMd)\n",
    "\n",
    "print(type(propWebsitePrompt))\n",
    "\n",
    "print(markdownTable(\n",
    "  headers=['Element', 'Size'],\n",
    "  values=[\n",
    "    [ 'Text', len(websiteMd) ],\n",
    "    [ 'Tokens', Llama2LangChain.get_num_tokens(websiteMd) ]\n",
    "  ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsupported message type: <class 'llama_index.core.base.llms.types.ChatMessage'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m propositionList: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m propositionNodes:\n\u001b[0;32m----> 5\u001b[0m   propositions \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLlama2LangChain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m   propositionList\u001b[38;5;241m.\u001b[39mextend(propositions)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(markdownTable(\n\u001b[1;32m     13\u001b[0m   headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m   values\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m   ]\n\u001b[1;32m     18\u001b[0m ))\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/src/prompts/proposition.py:80\u001b[0m, in \u001b[0;36mPropositionPrompt.chat\u001b[0;34m(self, llm, message)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastMessage \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m     78\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreatePrompt(message)\n\u001b[0;32m---> 80\u001b[0m chatResponse \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(chatResponse)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparseResponse(chatResponse)\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/language_models/llms.py:274\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    271\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m--> 274\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[1;32m    275\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    276\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    277\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    278\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    279\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    281\u001b[0m         )\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    284\u001b[0m     )\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/language_models/llms.py:256\u001b[0m, in \u001b[0;36mBaseLLM._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StringPromptValue(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, Sequence):\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39m\u001b[43mconvert_to_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/messages/__init__.py:247\u001b[0m, in \u001b[0;36mconvert_to_messages\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_messages\u001b[39m(\n\u001b[1;32m    237\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a sequence of messages to a list of messages.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m        List of messages (BaseMessages).\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/messages/__init__.py:247\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_messages\u001b[39m(\n\u001b[1;32m    237\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a sequence of messages to a list of messages.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m        List of messages (BaseMessages).\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n",
      "File \u001b[0;32m~/Repos/llamaindex-document-storage/llama-olama/lib/python3.11/site-packages/langchain_core/messages/__init__.py:231\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    227\u001b[0m     _message \u001b[38;5;241m=\u001b[39m _create_message_from_message_type(\n\u001b[1;32m    228\u001b[0m         msg_type, msg_content, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _message\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsupported message type: <class 'llama_index.core.base.llms.types.ChatMessage'>"
     ]
    }
   ],
   "source": [
    "propositionNodes = markdownTextSplitter(websiteMd)\n",
    "\n",
    "propositionList: list[str] = []\n",
    "for node in propositionNodes:\n",
    "  propositions = test.chat(\n",
    "    llm=Llama2LangChain,\n",
    "    message=node.page_content\n",
    "  )\n",
    "\n",
    "  propositionList.extend(propositions)\n",
    "\n",
    "print(markdownTable(\n",
    "  headers=['Element', 'Size'],\n",
    "  values=[\n",
    "    [ 'Documents', len(propositionNodes) ],\n",
    "    [ 'Propositions', len(propositionList) ]\n",
    "  ]\n",
    "))\n",
    "\n",
    "print(f\"Propositions:\\n```json\\n{json.dumps(propositionList)}\\n```\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.extend(testResults['semantic']['nodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Metadata\n",
    "\n",
    "The next step is we want to look at each node and try and find some additional metadata about each one.  This metadata can then assist the LLM in finding the correct chunks when doing the retrieval step.\n",
    "\n",
    "\n",
    "\n",
    "- Title Extraction\n",
    "- Q&A Extraction\n",
    "- Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-olama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
